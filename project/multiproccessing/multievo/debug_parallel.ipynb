{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evolve multiple integrators in parallel and compare the results with serial evolution.\n",
    "This script is needed to save timing relative to different configurations of the evolutions.\n",
    "It will be used for creating data of:\n",
    "\n",
    "- Serial timing with std numpy\n",
    "- Serial timing without std numpy (num threads = 1)\n",
    "- Parallel timing with std numpy\n",
    "- Parallel timing without std numpy (num threads = 1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import fireworks\n",
    "from fireworks.ic import ic_two_body as ic_two_body\n",
    "from fireworks.ic import ic_random_uniform\n",
    "\n",
    "from fireworks.nbodylib import dynamics as dyn\n",
    "from fireworks.nbodylib import integrators as intg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import os \n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def simulate(int_part,tstep=0.01,total_time = 10):\n",
    "\n",
    "   \n",
    "   integrator, particles = int_part\n",
    "   N_particles = len(particles)\n",
    "\n",
    "   integrator_name = integrator.__name__\n",
    "   print(\"integrator_name: \", integrator_name)\n",
    "\n",
    "   acc_list       = np.array([])\n",
    "   pos_list       = np.array([])\n",
    "   vel_list       = np.array([])\n",
    "   kinetic_list   = np.array([])\n",
    "   potential_list = np.array([])\n",
    "   energy_list    = np.array([])\n",
    "   \n",
    "   \n",
    "   for _ in range(int(total_time/tstep)):\n",
    "\n",
    "      particles, tstep, acc, jerk, _ = integrator(particles=particles, \n",
    "                                               tstep=tstep, \n",
    "                                               acceleration_estimator=dyn.acceleration_direct_vectorized,\n",
    "                                               softening=0.1,\n",
    "                                               )\n",
    "      \n",
    "      acc_list = np.append(acc_list, acc)\n",
    "      pos_list = np.append(pos_list, particles.pos)\n",
    "      vel_list = np.append(vel_list, particles.vel)\n",
    "\n",
    "      kinetic_list   = np.append(kinetic_list, particles.Ekin())\n",
    "      potential_list = np.append(potential_list, particles.Epot(softening=0.1))\n",
    "      energy_list    = np.append(energy_list, particles.Etot(softening=0.1))\n",
    "\n",
    "\n",
    "   acc_list = acc_list.reshape(int(total_time/tstep), N_particles, 3)\n",
    "   pos_list = pos_list.reshape(int(total_time/tstep), N_particles, 3)\n",
    "   vel_list = vel_list.reshape(int(total_time/tstep), N_particles, 3)\n",
    "\n",
    "   return {\"integrator_name\": integrator_name,\"acc_list\": acc_list, \"pos_list\": pos_list, \"vel_list\": vel_list, \"energy_list\": energy_list}\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "# key is what you want to plot, simulation_data is the output of integration_loop function\n",
    "def plot_sim(key: str, simulation_data: dict):\n",
    "\n",
    "    # Get the list of integrators from the simulation_data dictionary\n",
    "    integrators = list(simulation_data.keys())\n",
    "\n",
    "    # Create a grid plot with subplots for each integrator\n",
    "    fig, axs = plt.subplots(len(integrators),1, figsize=(8, 6 * len(integrators)),)\n",
    "\n",
    "    # Iterate over each integrator and plot pos_list\n",
    "    for i, integrator in enumerate(integrators):\n",
    "        data = simulation_data[integrator][key]\n",
    "\n",
    "        for j in range(data.shape[1]):\n",
    "            axs[i].scatter(data[:, j, 0], data[:, j, 1], label=f\"Body {j}\",s=.5)\n",
    "           # axs[i].plot(data[:, 1, 0], data[:, 1, 1], label=\"Star 2\")\n",
    "            axs[i].set_title(integrator)\n",
    "            axs[i].legend()\n",
    "\n",
    "    # Save the figure to a file\n",
    "    filename = \"parallel_plot.jpg\"\n",
    "    counter = 0 \n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = f\"parallel_plot_{counter}.jpg\"\n",
    "    print(\"saving plot to: \", filename)\n",
    "    plt.savefig(f\"{filename}\")\n",
    "    print(\"plot saved.\")\n",
    "    plt.close(fig)  # Close the figure to prevent it from being displayed\n",
    "\n",
    "\n",
    "# key is what you want to plot, simulation_data is the output of integration_loop function\n",
    "def plot_comparison(key: str, simulation_data_serial: dict, simulation_data_parallel: dict):\n",
    "\n",
    "    # Get the list of integrators from the simulation_data dictionary\n",
    "    integrators = list(simulation_data_serial.keys()) # assuming thet're the same for both dictionaries\n",
    "    \n",
    "    # Create a grid plot with subplots for each integrator\n",
    "    fig, axs = plt.subplots(len(integrators),2, figsize=(16, 6 * len(integrators)))\n",
    "\n",
    "    # Iterate over each integrator and plot pos_list\n",
    "    for i, integrator in enumerate(integrators):\n",
    "        data_serial   = simulation_data_serial[integrator][key]\n",
    "        data_parallel = simulation_data_parallel[integrator][key]\n",
    "\n",
    "        for j in range(data_serial.shape[1]):\n",
    "            axs[i,0].scatter(data_serial[:, j, 0], data_serial[:, j, 1], label=f\"Body {j}\",s=.5)\n",
    "            axs[i,0].set_title(integrator + \" Serial\")\n",
    "            axs[i,0].legend()\n",
    "\n",
    "            axs[i,1].scatter(data_parallel[:, j, 0], data_parallel[:, j, 1], label=f\"Body {j}\",s=.5)\n",
    "            axs[i,1].set_title(integrator + \" Parallel\")\n",
    "            axs[i,1].legend()\n",
    "\n",
    "    # Save the figure to a file\n",
    "    filename = \"comparison_plot.jpg\"\n",
    "    counter = 0 \n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = f\"comparison_plot_{counter}.jpg\"\n",
    "    print(\"saving plot to: \", filename)\n",
    "    plt.savefig(f\"{filename}\")\n",
    "    print(\"plot saved.\")\n",
    "    plt.close(fig)  # Close the figure to prevent it from being displayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parallel_evo(integrators,particles):\n",
    "    \n",
    "    #### MULTIPROCESSING ####\n",
    "    # define the number of processes\n",
    "    #N_CORES = multiprocessing.cpu_count() #Â in my case 4 cores\n",
    "    #N_INTEGRATORS = len(integrators)\n",
    "    # start a timer\n",
    "    #start = time.time()\n",
    "    \n",
    "    # create a pool of processes\n",
    "    pool = ThreadPool(2)\n",
    "\n",
    "\n",
    "    # submit multiple instances of the function full_evo \n",
    "    # - starmap_async: allows to run the processes with a (iterable) list of arguments\n",
    "    # - map_async    : is a similar function, supporting a single argument\n",
    "\n",
    "    future_results = pool.map_async(simulate, [(integrator,particles) for integrator in integrators])\n",
    "\n",
    "    # to get the results all processes must have been completed\n",
    "    # the get() function is therefore _blocking_ (equivalent to join) \n",
    "    results = future_results.get()\n",
    "  \n",
    "\n",
    "    # close the pool\n",
    "    # Warning multiprocessing.pool objects have internal resources that need to be properly managed \n",
    "    # (like any other resource) by using the pool as a context manager or by calling close() and terminate() manually. Failure to do this can lead to the process hanging on finalization.\n",
    "    pool.close()\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrator_name:  integrator_leapfrog\n"
     ]
    }
   ],
   "source": [
    "n_particles = 2\n",
    "n_simulations = 1\n",
    "\n",
    "particles = ic_random_uniform(n_particles, [1,3],[1,3],[1,3])\n",
    "period = 10\n",
    "\"\"\"\"\n",
    "Here I will parallelize the same simulation with the same integrators. \n",
    "\n",
    "integrators = [intg.integrator_euler,\n",
    "                intg.integrator_hermite,\n",
    "                intg.integrator_leapfrog,\n",
    "                intg.integrator_heun,\n",
    "                intg.integrator_rk4,\n",
    "                ]\n",
    "\"\"\"\n",
    "# Using only leapfrog integrator\n",
    "start_parallel = time.time()\n",
    "integrators = [intg.integrator_leapfrog for _ in range(n_simulations)]\n",
    "\n",
    "results = parallel_evo(integrators,particles)\n",
    "end_parallel = time.time()\n",
    "\n",
    "parallel_time = end_parallel - start_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decide not to save the results of the simulations, but to save data needed for comparison only\n",
    "# I already have a script that shows the results of the simulations --> multievolution_parallel.py\n",
    "# Dai me li salvo lo stesso\n",
    "\n",
    "save_me = {\"n_particles\": n_particles,\n",
    "  \"n_simulations\": n_simulations, \n",
    "  \"integrators\": integrators, \n",
    "    \"parallel_time\":parallel_time, \n",
    "    \"serial_time\": parallel_time,\n",
    "    \"std_numpy\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
